{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  To activate MPS on M1 MAC\n",
    "\n",
    "### 1. Run these in Terminal\n",
    "```shell\n",
    "chmod +x ~/Downloads/Miniforge3-MacOSX-arm64.sh\n",
    "sh ~/Downloads/Miniforge3-MacOSX-arm64.sh\n",
    "source ~/miniforge3/bin/activate\n",
    "```\n",
    "\n",
    "### 2. Create a conda environment :\n",
    "```bash\n",
    "mkdir pytorch\n",
    "cd pytorch\n",
    "```\n",
    "### 3. Run these:\n",
    "\n",
    "```shell\n",
    "conda create --prefix ./env python=3.8\n",
    "conda activate ./env\n",
    "```\n",
    "\n",
    "### 4.Install torch with MPS backend. Note that torch version should be >= 1.12.0\n",
    "```bash\n",
    "pip3 install torch torchvision torchaudio\n",
    "```\n",
    "### 5. install other DS libraries:\n",
    "```bash\n",
    "conda install jupyter pandas numpy matplotlib \n",
    "```\n",
    "### 6. Run \n",
    "```shell\n",
    "jupyter notebook\n",
    "```\n",
    "### 7. test the MPS backend with provided function.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.transforms import Normalize, ToTensor\n",
    "import torch.nn as nn  \n",
    "import torch.optim as optim  \n",
    "import torch.nn.functional as F  \n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import time\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_backend():\n",
    "    global device\n",
    "    print(f\" Pytorch Version {torch.__version__}\")\n",
    "    print (f' MPS backend is bulit? {torch.backends.mps.is_built()}')\n",
    "    print( f' MPS backend is available {torch.backends.mps.is_available()}')\n",
    "    device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "    print(f' Device is set to {device}')\n",
    "    return \n",
    "\n",
    "\n",
    "# load data in\n",
    "\n",
    "def load_data(val_split=0.8):\n",
    "    \n",
    "    train_set = datasets.EMNIST(root=\"data\", split=\"balanced\", train=True, transform=transforms.Compose([ToTensor()]))\n",
    "    test_set = datasets.EMNIST(root=\"data\", split=\"balanced\", train=False, transform=transforms.Compose([ToTensor()]))\n",
    "    train_ = torch.utils.data.DataLoader(train_set, shuffle=True)\n",
    "\n",
    "    split_ = int(val_split*(len(train_)))  \n",
    "    valid_ = len(train_) - split_ \n",
    "\n",
    "    train_set, val_set = torch.utils.data.random_split(train_set, [split_, valid_]) \n",
    "\n",
    "    print(f' train size: {len(train_set)}, val size: {len(val_set)} , test size: {len(test_set)} ')\n",
    "    classes = test_set.classes\n",
    "    return train_set, val_set, test_set,classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pytorch Version 1.12.0\n",
      " MPS backend is bulit? True\n",
      " MPS backend is available True\n",
      " Device is set to mps\n",
      " train size: 90240, val size: 22560 , test size: 18800 \n"
     ]
    }
   ],
   "source": [
    "check_backend()\n",
    "train_set, val_set, test_set,classes = load_data(val_split=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_SIZE = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# easily tunable model\n",
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.conv_1 = nn.Conv2d(in_channels=1, out_channels=64,kernel_size=3,stride=1,padding=1)\n",
    "        self.relu_1 = nn.ReLU()\n",
    "        \n",
    "        self.conv_2 =  nn.Conv2d(in_channels=64, out_channels=64,kernel_size=3,stride=1,padding=1)\n",
    "        self.relu_2 =  nn.ReLU()\n",
    "        \n",
    "        self.max_3  =  nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv_3 =  nn.Conv2d(in_channels=64, out_channels=128,kernel_size=3,stride=1,padding=1)\n",
    "        self.bn_3   =  nn.BatchNorm2d(128)\n",
    "        self.relu_3 =  nn.ReLU()\n",
    "         \n",
    "        self.out    =  nn.Sequential(nn.Linear(25088, 64),nn.ReLU(),nn.Linear(64, OUTPUT_SIZE))\n",
    "         \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_1 (x)\n",
    "        x = self.relu_1 (x)\n",
    "        \n",
    "        x = self.conv_2 (x)\n",
    "        x = self.relu_2 (x)\n",
    "        \n",
    "        x = self.max_3  (x)\n",
    "        x = self.conv_3 (x)\n",
    "        x = self.bn_3 (x)\n",
    "        x = self.relu_3(x)\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.out(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, Validate, Test Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion):\n",
    "  \n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=256, shuffle=True)\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    train_loss = 0\n",
    "    \n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        #3inputs, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        _, prediction = torch.max(outputs.data, 1)  \n",
    "        total += labels.size(0)\n",
    "        correct += (prediction == labels).sum().item()\n",
    "\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "    train_acc = 100 * correct / total\n",
    "    \n",
    "    return model, train_loss, train_acc  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, criterion):\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(val_set, batch_size=256, shuffle=True)\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    val_loss = 0 \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            _, prediction = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (prediction == labels).sum().item()\n",
    "\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_acc = 100 * correct / total\n",
    "\n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(test_set, batch_size=256, shuffle=True)\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        test_acc = 100 * correct / total\n",
    "\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_explore(epochs = 2):\n",
    " \n",
    "    model = CNN()\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()  \n",
    "    optimizer = optim.Adam(model.parameters(), lr = 0.001)  \n",
    "    print(model)\n",
    "\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    \n",
    "    time_total = 0\n",
    "    \n",
    "    for epoch in range(epochs): \n",
    "        time_start = time.time()\n",
    "        model, train_loss, train_acc = train(model, optimizer, criterion)\n",
    "        val_loss, val_acc = validate(model, criterion)\n",
    "        time_end = time.time()\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "        \n",
    "        time_duration = round(time_end - time_start, 2)\n",
    "        time_total += time_duration\n",
    "        \n",
    "      \n",
    "        print(f'Epoch {epoch},\\t train acc: {train_acc:.3f},train loss: {train_loss:.5f},\\t val acc: {val_acc:.3f}, val loss: {val_loss:.5f},  \\t time: {time_duration}s')\n",
    "    test_acc = test(model)\n",
    "\n",
    "    results = OrderedDict()\n",
    "    results['train_losses'] = [round(x, 4) for x in train_losses]\n",
    "    results['val_losses'] = [round(x, 4) for x in val_losses]\n",
    "    results['train_accs'] = [round(x, 2) for x in train_accs]\n",
    "    results['val_accs'] = [round(x, 2) for x in val_accs]\n",
    "    results['train_acc'] = round(train_acc, 2)\n",
    "    results['val_acc'] = round(val_acc, 2)\n",
    "    results['test_acc'] = round(test_acc, 2)\n",
    "    results['time_total'] = round(time_total, 2)\n",
    "    \n",
    "    return results, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv_1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu_1): ReLU()\n",
      "  (conv_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu_2): ReLU()\n",
      "  (max_3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv_3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn_3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu_3): ReLU()\n",
      "  (out): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=47, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch 0,\t train acc: 60.559,train loss: 1.41203,\t val acc: 78.444, val loss: 0.68951,  \t time: 15.45s\n",
      "Epoch 1,\t train acc: 81.502,train loss: 0.57966,\t val acc: 82.234, val loss: 0.56284,  \t time: 15.67s\n",
      "Epoch 2,\t train acc: 84.031,train loss: 0.48301,\t val acc: 83.910, val loss: 0.49325,  \t time: 15.52s\n",
      "Epoch 3,\t train acc: 85.294,train loss: 0.43730,\t val acc: 83.932, val loss: 0.48710,  \t time: 15.39s\n",
      "Epoch 4,\t train acc: 86.102,train loss: 0.40515,\t val acc: 85.058, val loss: 0.46063,  \t time: 15.58s\n",
      "Epoch 5,\t train acc: 86.899,train loss: 0.37836,\t val acc: 85.186, val loss: 0.46021,  \t time: 15.32s\n",
      "Epoch 6,\t train acc: 87.405,train loss: 0.35797,\t val acc: 85.514, val loss: 0.43620,  \t time: 15.28s\n",
      "Epoch 7,\t train acc: 88.068,train loss: 0.33826,\t val acc: 85.860, val loss: 0.42880,  \t time: 15.27s\n",
      "Epoch 8,\t train acc: 88.361,train loss: 0.32161,\t val acc: 86.352, val loss: 0.42183,  \t time: 15.24s\n",
      "Epoch 9,\t train acc: 88.874,train loss: 0.30366,\t val acc: 85.403, val loss: 0.45510,  \t time: 15.38s\n",
      "Epoch 10,\t train acc: 89.235,train loss: 0.28789,\t val acc: 86.144, val loss: 0.43379,  \t time: 15.26s\n",
      "Epoch 11,\t train acc: 90.011,train loss: 0.26932,\t val acc: 85.913, val loss: 0.43893,  \t time: 15.52s\n",
      "Epoch 12,\t train acc: 90.318,train loss: 0.25779,\t val acc: 85.887, val loss: 0.45514,  \t time: 15.27s\n",
      "Epoch 13,\t train acc: 90.793,train loss: 0.24110,\t val acc: 85.674, val loss: 0.46705,  \t time: 15.27s\n",
      "Epoch 14,\t train acc: 91.044,train loss: 0.23234,\t val acc: 86.024, val loss: 0.46050,  \t time: 15.27s\n",
      "Epoch 15,\t train acc: 91.664,train loss: 0.21650,\t val acc: 85.359, val loss: 0.49617,  \t time: 15.27s\n",
      "Epoch 16,\t train acc: 92.090,train loss: 0.20133,\t val acc: 85.660, val loss: 0.49107,  \t time: 15.26s\n",
      "Epoch 17,\t train acc: 92.531,train loss: 0.18958,\t val acc: 85.474, val loss: 0.50894,  \t time: 15.29s\n",
      "Epoch 18,\t train acc: 92.810,train loss: 0.18239,\t val acc: 85.412, val loss: 0.53205,  \t time: 15.26s\n",
      "Epoch 19,\t train acc: 93.250,train loss: 0.17009,\t val acc: 84.481, val loss: 0.56917,  \t time: 15.24s\n",
      "Epoch 20,\t train acc: 93.647,train loss: 0.16000,\t val acc: 84.863, val loss: 0.56626,  \t time: 15.25s\n",
      "Epoch 21,\t train acc: 94.119,train loss: 0.14873,\t val acc: 85.049, val loss: 0.57645,  \t time: 15.24s\n",
      "Epoch 22,\t train acc: 94.379,train loss: 0.14125,\t val acc: 85.137, val loss: 0.57871,  \t time: 15.3s\n",
      "Epoch 23,\t train acc: 94.845,train loss: 0.13120,\t val acc: 85.386, val loss: 0.60246,  \t time: 15.24s\n",
      "Epoch 24,\t train acc: 94.976,train loss: 0.12640,\t val acc: 85.168, val loss: 0.60464,  \t time: 15.24s\n",
      "Epoch 25,\t train acc: 95.324,train loss: 0.11877,\t val acc: 84.517, val loss: 0.66515,  \t time: 15.38s\n",
      "Epoch 26,\t train acc: 95.591,train loss: 0.11251,\t val acc: 84.437, val loss: 0.68296,  \t time: 15.48s\n",
      "Epoch 27,\t train acc: 95.834,train loss: 0.10470,\t val acc: 84.277, val loss: 0.71978,  \t time: 15.6s\n",
      "Epoch 28,\t train acc: 96.157,train loss: 0.09691,\t val acc: 84.557, val loss: 0.70788,  \t time: 15.29s\n",
      "Epoch 29,\t train acc: 96.477,train loss: 0.09070,\t val acc: 84.681, val loss: 0.74149,  \t time: 15.47s\n",
      "test acc: 84.32\n",
      "total training time: 460.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results,model = model_explore(epochs= 30)\n",
    "\n",
    "print(f'test acc: {results[\"test_acc\"]}')\n",
    "print(f'total training time: {results[\"time_total\"]}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'EMNIST_CNN_model_22JUL2022.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = CNN()\n",
    "loaded_model.load_state_dict(torch.load('EMNIST_CNN_model_22JUL2022.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv_1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu_1): ReLU()\n",
       "  (conv_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu_2): ReLU()\n",
       "  (max_3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv_3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn_3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu_3): ReLU()\n",
       "  (out): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=47, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv_1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu_1): ReLU()\n",
       "  (conv_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu_2): ReLU()\n",
       "  (max_3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv_3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn_3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu_3): ReLU()\n",
       "  (out): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=47, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preicted : \"g\", Actual:\"g\" \t \n",
      "Preicted : \"e\", Actual:\"e\" \t \n",
      "Preicted : \"9\", Actual:\"9\" \t \n",
      "Preicted : \"Q\", Actual:\"Q\" \t \n",
      "Preicted : \"q\", Actual:\"q\" \t \n",
      "Preicted : \"X\", Actual:\"X\" \t \n",
      "Preicted : \"E\", Actual:\"E\" \t \n",
      "Preicted : \"B\", Actual:\"B\" \t \n",
      "Preicted : \"3\", Actual:\"3\" \t \n",
      "Preicted : \"L\", Actual:\"C\" \t Not correct\n",
      "Preicted : \"G\", Actual:\"G\" \t \n",
      "Preicted : \"7\", Actual:\"7\" \t \n",
      "Preicted : \"Z\", Actual:\"2\" \t Not correct\n",
      "Preicted : \"G\", Actual:\"G\" \t \n",
      "Preicted : \"0\", Actual:\"G\" \t Not correct\n",
      "Preicted : \"R\", Actual:\"R\" \t \n",
      "Preicted : \"6\", Actual:\"6\" \t \n",
      "Preicted : \"8\", Actual:\"q\" \t Not correct\n",
      "Preicted : \"S\", Actual:\"S\" \t \n",
      "Preicted : \"r\", Actual:\"r\" \t \n",
      "Preicted : \"T\", Actual:\"T\" \t \n",
      "Preicted : \"8\", Actual:\"8\" \t \n",
      "Preicted : \"4\", Actual:\"4\" \t \n",
      "Preicted : \"Z\", Actual:\"Z\" \t \n",
      "Preicted : \"e\", Actual:\"e\" \t \n",
      "Preicted : \"F\", Actual:\"f\" \t Not correct\n",
      "Preicted : \"e\", Actual:\"e\" \t \n",
      "Preicted : \"X\", Actual:\"X\" \t \n",
      "Preicted : \"b\", Actual:\"b\" \t \n",
      "Preicted : \"8\", Actual:\"G\" \t Not correct\n",
      "Preicted : \"C\", Actual:\"C\" \t \n",
      "Preicted : \"L\", Actual:\"L\" \t \n",
      "Preicted : \"S\", Actual:\"S\" \t \n",
      "Preicted : \"F\", Actual:\"f\" \t Not correct\n",
      "Preicted : \"n\", Actual:\"n\" \t \n",
      "Preicted : \"C\", Actual:\"C\" \t \n",
      "Preicted : \"K\", Actual:\"K\" \t \n",
      "Preicted : \"Q\", Actual:\"Q\" \t \n",
      "Preicted : \"C\", Actual:\"C\" \t \n",
      "Preicted : \"1\", Actual:\"1\" \t \n",
      "Preicted : \"b\", Actual:\"b\" \t \n",
      "Preicted : \"b\", Actual:\"b\" \t \n",
      "Preicted : \"q\", Actual:\"q\" \t \n",
      "Preicted : \"N\", Actual:\"N\" \t \n",
      "Preicted : \"3\", Actual:\"3\" \t \n",
      "Preicted : \"5\", Actual:\"5\" \t \n",
      "Preicted : \"n\", Actual:\"n\" \t \n",
      "Preicted : \"P\", Actual:\"P\" \t \n",
      "Preicted : \"1\", Actual:\"1\" \t \n",
      "Preicted : \"6\", Actual:\"E\" \t Not correct\n",
      "Preicted : \"G\", Actual:\"6\" \t Not correct\n",
      "Preicted : \"V\", Actual:\"V\" \t \n",
      "Preicted : \"g\", Actual:\"q\" \t Not correct\n",
      "Preicted : \"h\", Actual:\"L\" \t Not correct\n",
      "Preicted : \"a\", Actual:\"Q\" \t Not correct\n",
      "Preicted : \"H\", Actual:\"H\" \t \n",
      "Preicted : \"q\", Actual:\"q\" \t \n",
      "Preicted : \"S\", Actual:\"S\" \t \n",
      "Preicted : \"Y\", Actual:\"Y\" \t \n",
      "Preicted : \"Z\", Actual:\"Z\" \t \n",
      "Preicted : \"0\", Actual:\"0\" \t \n",
      "Preicted : \"e\", Actual:\"e\" \t \n",
      "Preicted : \"X\", Actual:\"X\" \t \n",
      "Preicted : \"G\", Actual:\"G\" \t \n",
      "Preicted : \"X\", Actual:\"X\" \t \n",
      "Preicted : \"2\", Actual:\"2\" \t \n",
      "Preicted : \"3\", Actual:\"3\" \t \n",
      "Preicted : \"q\", Actual:\"q\" \t \n",
      "Preicted : \"I\", Actual:\"I\" \t \n",
      "Preicted : \"a\", Actual:\"a\" \t \n",
      "Preicted : \"d\", Actual:\"d\" \t \n",
      "Preicted : \"Q\", Actual:\"Q\" \t \n",
      "Preicted : \"S\", Actual:\"S\" \t \n",
      "Preicted : \"6\", Actual:\"J\" \t Not correct\n",
      "Preicted : \"e\", Actual:\"e\" \t \n",
      "Preicted : \"N\", Actual:\"N\" \t \n",
      "Preicted : \"F\", Actual:\"f\" \t Not correct\n",
      "Preicted : \"X\", Actual:\"X\" \t \n",
      "Preicted : \"3\", Actual:\"3\" \t \n",
      "Preicted : \"Z\", Actual:\"Z\" \t \n",
      "Preicted : \"r\", Actual:\"r\" \t \n",
      "Preicted : \"H\", Actual:\"H\" \t \n",
      "Preicted : \"S\", Actual:\"S\" \t \n",
      "Preicted : \"X\", Actual:\"X\" \t \n",
      "Preicted : \"C\", Actual:\"C\" \t \n",
      "Preicted : \"W\", Actual:\"W\" \t \n",
      "Preicted : \"V\", Actual:\"V\" \t \n",
      "Preicted : \"G\", Actual:\"B\" \t Not correct\n",
      "Preicted : \"D\", Actual:\"D\" \t \n",
      "Preicted : \"f\", Actual:\"f\" \t \n",
      "Preicted : \"T\", Actual:\"T\" \t \n",
      "Preicted : \"G\", Actual:\"G\" \t \n",
      "Preicted : \"W\", Actual:\"W\" \t \n",
      "Preicted : \"Q\", Actual:\"Q\" \t \n",
      "Preicted : \"D\", Actual:\"D\" \t \n",
      "Preicted : \"1\", Actual:\"1\" \t \n",
      "Preicted : \"C\", Actual:\"C\" \t \n",
      "Preicted : \"9\", Actual:\"q\" \t Not correct\n",
      "Preicted : \"5\", Actual:\"5\" \t \n",
      "Preicted : \"h\", Actual:\"h\" \t \n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "\n",
    "    x,y = test_set[i][0], test_set [i][1]\n",
    "    x = x.unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        pred = loaded_model(x)\n",
    "        predicted , actual = classes[pred[0].argmax(0)],classes[y]\n",
    "        if  predicted != actual:\n",
    "            flag = 'Not correct'\n",
    "        else :\n",
    "             flag = ''\n",
    "        print(f'Preicted : \"{predicted}\", Actual:\"{actual}\" \\t {flag}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
